{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from bs4 import element\n",
    "import re\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting links and metadata from https://www.n-tv.de/news.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta_data():\n",
    "    news = soup(requests.get('https://www.n-tv.de/news.xml').text, features=\"xml\")\n",
    "    \n",
    "    keywords = ['Ukraine','Russland', 'Wladimir Putin']  # ToDo Keywords spezifizieren\n",
    "    \n",
    "    filtered_news = [url for url in news.find('urlset').find_all('url', recursive=False) if len(set(keywords).intersection(set(url.find('news:keywords').text.split(', '))))!=0]\n",
    "    \n",
    "    return_list = []\n",
    "    for new in filtered_news:\n",
    "        dictionary = {\n",
    "        'url' : new.find('loc').text,\n",
    "        'title' : new.find('news:title').text,\n",
    "        'date' : new.find('news:publication_date').text,\n",
    "        'keywords' : new.find('news:keywords').text\n",
    "        }\n",
    "        dictionary = { **dictionary, 'figcaption' : new.find('image:caption').text } if new.find('image:caption') else dictionary\n",
    "        return_list += [dictionary]\n",
    "        \n",
    "    return return_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting text and ... from urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.n-tv.de/panorama/Hunderte-ukrainische-Lehrer-bewerben-sich-in-Deutschland-article23286199.html'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = extract_meta_data()[5]['url']\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(article_soup.find('span', class_='article__kicker').children)[0])\n",
    "isinstance(list(article_soup.find('span', class_='article__kicker').children)[0],element.NavigableString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(article_soup.find('span', class_='article__kicker').children)[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_content(url):\n",
    "    article_soup = soup(requests.get(url).text)\n",
    "    kicker = article_soup.find('span', class_='article__kicker').text\n",
    "    title =  article_soup.find('span', class_='article__headline').text\n",
    "    author = article_soup.find('span', class_='article__author').text if article_soup.find('span', class_='article__author') else ''\n",
    "    date = article_soup.find('span', class_='article__date').text\n",
    "    strong = article_soup.find('strong').text if article_soup.find('strong') else ''\n",
    "    article_text = article_soup.find('div', class_='article__text')\n",
    "    text = strong + ' '.join([x for p in article_text.find_all(lambda x: x.name =='p') for x in [i for i in p.contents if isinstance(i,element.NavigableString) if i]])\n",
    "    subheadline = '. '.join([h2.text for h2 in article_text.find_all('h2')])\n",
    "    \n",
    "    return_dict = {\n",
    "        'title': title,\n",
    "        'kicker': kicker,\n",
    "        'author':author,\n",
    "        'date':date,\n",
    "        'text':text,\n",
    "        'subheadlines': subheadline,\n",
    "        'url': url\n",
    "    }\n",
    "    \n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Ukraine: Über 3800 zivile Todesopfer seit Ausbruch des russischen Angriffskrieges',\n",
       " 'kicker': '\\n                    Dunkelziffer wohl deutlich höher',\n",
       " 'author': '',\n",
       " 'date': '25.04.2022, 12:22 Uhr',\n",
       " 'text': 'Durch den vor gut zwei Monaten begonnenen russischen Angriffskrieg in der Ukraine sind nach ukrainischen Angaben mindestens 3818 Zivilisten getötet worden. \"Verletzte: mehr als 4000\", teilte die ukrainische Generalstaatsanwältin Iryna Wenediktowa der Nachrichtenagentur Interfax-Ukraine am Montag mit. (Foto: dpa)  Die Statistik sei jedoch unvollständig, da die Behörden zu vielen Orten, darunter zur blockierten Hafenstadt Mariupol, keinen Zugang hätten. Aktuell geht die Staatsanwaltschaft dabei von mindestens 215 getöteten und 391 verletzten Kindern aus. Die Vereinten Nationen haben bisher rund 2500 zivile Tote erfasst, gehen aber ebenso wie Kiew von weitaus höheren zivilen Opferzahlen aus. ',\n",
       " 'subheadlines': '',\n",
       " 'url': 'https://www.n-tv.de/ticker/Ukraine-Uber-3800-zivile-Todesopfer-seit-Ausbruch-des-russischen-Angriffskrieges-article23288045.html'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_content(extract_meta_data()[5]['url'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
